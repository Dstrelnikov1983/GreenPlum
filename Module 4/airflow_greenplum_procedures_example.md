# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä: –ó–∞–ø—É—Å–∫ —Ö—Ä–∞–Ω–∏–º–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä—ã GreenPlum –∏–∑ Apache Airflow

## üìã –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è

–í —ç—Ç–æ–º –ø—Ä–∏–º–µ—Ä–µ –º—ã —Å–æ–∑–¥–∞–¥–∏–º –ø–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å, –≥–¥–µ Apache Airflow –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å —Ö—Ä–∞–Ω–∏–º—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –≤ GreenPlum –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ETL –æ–ø–µ—Ä–∞—Ü–∏–π.

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫–∞–∑–æ–≤ e-commerce –º–∞–≥–∞–∑–∏–Ω–∞
- –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –∑–∞–∫–∞–∑–æ–≤ –∏–∑ staging
- –†–∞—Å—á–µ—Ç –¥–Ω–µ–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏—Ç—Ä–∏–Ω –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Yandex Cloud Infrastructure                 ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Apache Airflow  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   GreenPlum     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Remote Server) ‚îÇ  SSL    ‚îÇ   Database      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ         ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Scheduler     ‚îÇ         ‚îÇ  - Master Node  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Workers       ‚îÇ         ‚îÇ  - Segments     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Web UI        ‚îÇ         ‚îÇ  - Procedures   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ –ß—Ç–æ –º—ã —Å–æ–∑–¥–∞–¥–∏–º

1. **–•—Ä–∞–Ω–∏–º—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –≤ GreenPlum** - –¥–ª—è –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏
2. **DAG –≤ Airflow** - –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏
3. **Connection –Ω–∞—Å—Ç—Ä–æ–π–∫–∏** - –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ** - –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

---

## –ß–∞—Å—Ç—å 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ GreenPlum (30 –º–∏–Ω—É—Ç)

### –®–∞–≥ 1.1: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –∏ —Ç–∞–±–ª–∏—Ü

–ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ GreenPlum –∏ —Å–æ–∑–¥–∞–π—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:

```bash
# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ GreenPlum
psql "host=c-xxxxx.rw.mdb.yandexcloud.net port=6432 dbname=postgres user=admin sslmode=require"
```

```sql
-- ==========================================
-- 1. –°–û–ó–î–ê–ù–ò–ï –°–•–ï–ú–´ –î–õ–Ø ETL –ü–†–û–¶–ï–°–°–û–í
-- ==========================================

CREATE SCHEMA IF NOT EXISTS ecommerce;

-- ==========================================
-- 2. STAGING –¢–ê–ë–õ–ò–¶–ê –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò –ó–ê–ö–ê–ó–û–í
-- ==========================================

CREATE TABLE ecommerce.orders_staging (
    order_id BIGINT,
    customer_id INTEGER,
    product_id INTEGER,
    quantity INTEGER,
    unit_price NUMERIC(10,2),
    discount_percent NUMERIC(5,2),
    order_date DATE,
    order_time TIME,
    status VARCHAR(20),
    region VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) DISTRIBUTED RANDOMLY;

-- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ —Ç–∞–±–ª–∏—Ü–µ
COMMENT ON TABLE ecommerce.orders_staging IS 
'–í—Ä–µ–º–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–∫–∞–∑–æ–≤ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π';

-- ==========================================
-- 3. PRODUCTION –¢–ê–ë–õ–ò–¶–ê –ó–ê–ö–ê–ó–û–í
-- ==========================================

CREATE TABLE ecommerce.orders (
    order_id BIGINT PRIMARY KEY,
    customer_id INTEGER,
    product_id INTEGER,
    quantity INTEGER,
    unit_price NUMERIC(10,2),
    discount_amount NUMERIC(10,2),
    total_amount NUMERIC(10,2),
    order_date DATE,
    order_time TIME,
    status VARCHAR(20),
    region VARCHAR(50),
    processed_at TIMESTAMP,
    load_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) DISTRIBUTED BY (order_id)
PARTITION BY RANGE (order_date)
(
    START (DATE '2025-01-01') INCLUSIVE
    END (DATE '2026-01-01') EXCLUSIVE
    EVERY (INTERVAL '1 month')
);

COMMENT ON TABLE ecommerce.orders IS 
'–û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∑–∞–∫–∞–∑–æ–≤ —Å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º';

-- ==========================================
-- 4. –¢–ê–ë–õ–ò–¶–ê –î–ù–ï–í–ù–´–• –ê–ì–†–ï–ì–ê–¢–û–í
-- ==========================================

CREATE TABLE ecommerce.daily_sales_summary (
    summary_date DATE PRIMARY KEY,
    total_orders INTEGER,
    total_revenue NUMERIC(15,2),
    total_discount NUMERIC(15,2),
    avg_order_value NUMERIC(10,2),
    unique_customers INTEGER,
    unique_products INTEGER,
    top_region VARCHAR(50),
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) DISTRIBUTED REPLICATED;

COMMENT ON TABLE ecommerce.daily_sales_summary IS 
'–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –ø—Ä–æ–¥–∞–∂ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞';

-- ==========================================
-- 5. –¢–ê–ë–õ–ò–¶–ê –õ–û–ì–û–í –í–´–ü–û–õ–ù–ï–ù–ò–Ø ETL
-- ==========================================

CREATE TABLE ecommerce.etl_execution_log (
    execution_id SERIAL PRIMARY KEY,
    procedure_name VARCHAR(100),
    execution_date DATE,
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    duration_seconds INTEGER,
    rows_processed INTEGER,
    status VARCHAR(20),
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) DISTRIBUTED RANDOMLY;

COMMENT ON TABLE ecommerce.etl_execution_log IS 
'–õ–æ–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ETL –ø—Ä–æ—Ü–µ–¥—É—Ä –¥–ª—è –∞—É–¥–∏—Ç–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞';

-- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
\dt ecommerce.*
```

### –®–∞–≥ 1.2: –°–æ–∑–¥–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–º–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä—ã #1 - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫–∞–∑–æ–≤

```sql
-- ==========================================
-- –ü–†–û–¶–ï–î–£–†–ê 1: –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–ö–ê–ó–û–í –ò–ó STAGING
-- ==========================================

CREATE OR REPLACE PROCEDURE ecommerce.process_orders_from_staging()
LANGUAGE plpgsql
AS $$
DECLARE
    v_start_time TIMESTAMP;
    v_end_time TIMESTAMP;
    v_rows_processed INTEGER := 0;
    v_execution_id INTEGER;
BEGIN
    -- –§–∏–∫—Å–∏—Ä—É–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
    v_start_time := CLOCK_TIMESTAMP();
    
    -- –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ –Ω–∞—á–∞–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    INSERT INTO ecommerce.etl_execution_log 
    (procedure_name, execution_date, start_time, status)
    VALUES 
    ('process_orders_from_staging', CURRENT_DATE, v_start_time, 'RUNNING')
    RETURNING execution_id INTO v_execution_id;
    
    RAISE NOTICE 'Starting order processing. Execution ID: %', v_execution_id;
    
    -- ==========================================
    -- –®–ê–ì 1: –í–ê–õ–ò–î–ê–¶–ò–Ø –î–ê–ù–ù–´–•
    -- ==========================================
    
    -- –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    DELETE FROM ecommerce.orders_staging
    WHERE order_id IS NULL 
       OR customer_id IS NULL 
       OR product_id IS NULL
       OR quantity <= 0
       OR unit_price < 0;
    
    GET DIAGNOSTICS v_rows_processed = ROW_COUNT;
    RAISE NOTICE 'Removed % invalid records from staging', v_rows_processed;
    
    -- ==========================================
    -- –®–ê–ì 2: –†–ê–°–ß–ï–¢ –ü–†–û–ò–ó–í–û–î–ù–´–• –ü–û–õ–ï–ô
    -- ==========================================
    
    -- –û–±–Ω–æ–≤–ª—è–µ–º staging —Å –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    UPDATE ecommerce.orders_staging
    SET 
        created_at = CURRENT_TIMESTAMP;
    
    -- ==========================================
    -- –®–ê–ì 3: –ó–ê–ì–†–£–ó–ö–ê –í PRODUCTION (UPSERT)
    -- ==========================================
    
    -- –ò—Å–ø–æ–ª—å–∑—É–µ–º INSERT ... ON CONFLICT –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
    WITH staged_orders AS (
        SELECT 
            order_id,
            customer_id,
            product_id,
            quantity,
            unit_price,
            -- –í—ã—á–∏—Å–ª—è–µ–º discount_amount
            ROUND(unit_price * quantity * COALESCE(discount_percent, 0) / 100, 2) as discount_amount,
            -- –í—ã—á–∏—Å–ª—è–µ–º total_amount
            ROUND(unit_price * quantity - 
                  (unit_price * quantity * COALESCE(discount_percent, 0) / 100), 2) as total_amount,
            order_date,
            order_time,
            status,
            region,
            CURRENT_TIMESTAMP as processed_at
        FROM ecommerce.orders_staging
    )
    INSERT INTO ecommerce.orders (
        order_id, customer_id, product_id, quantity, unit_price,
        discount_amount, total_amount, order_date, order_time,
        status, region, processed_at
    )
    SELECT * FROM staged_orders
    ON CONFLICT (order_id) DO UPDATE SET
        customer_id = EXCLUDED.customer_id,
        product_id = EXCLUDED.product_id,
        quantity = EXCLUDED.quantity,
        unit_price = EXCLUDED.unit_price,
        discount_amount = EXCLUDED.discount_amount,
        total_amount = EXCLUDED.total_amount,
        order_date = EXCLUDED.order_date,
        order_time = EXCLUDED.order_time,
        status = EXCLUDED.status,
        region = EXCLUDED.region,
        processed_at = EXCLUDED.processed_at,
        load_timestamp = CURRENT_TIMESTAMP;
    
    GET DIAGNOSTICS v_rows_processed = ROW_COUNT;
    RAISE NOTICE 'Processed % orders into production table', v_rows_processed;
    
    -- ==========================================
    -- –®–ê–ì 4: –û–ß–ò–°–¢–ö–ê STAGING
    -- ==========================================
    
    TRUNCATE TABLE ecommerce.orders_staging;
    RAISE NOTICE 'Staging table truncated';
    
    -- ==========================================
    -- –®–ê–ì 5: –û–ë–ù–û–í–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò
    -- ==========================================
    
    ANALYZE ecommerce.orders;
    RAISE NOTICE 'Statistics updated for orders table';
    
    -- –§–∏–∫—Å–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    v_end_time := CLOCK_TIMESTAMP();
    
    UPDATE ecommerce.etl_execution_log
    SET 
        end_time = v_end_time,
        duration_seconds = EXTRACT(EPOCH FROM (v_end_time - v_start_time))::INTEGER,
        rows_processed = v_rows_processed,
        status = 'SUCCESS'
    WHERE execution_id = v_execution_id;
    
    RAISE NOTICE 'Order processing completed successfully. Duration: % seconds', 
                 EXTRACT(EPOCH FROM (v_end_time - v_start_time))::INTEGER;
    
EXCEPTION
    WHEN OTHERS THEN
        -- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
        UPDATE ecommerce.etl_execution_log
        SET 
            end_time = CLOCK_TIMESTAMP(),
            status = 'FAILED',
            error_message = SQLERRM
        WHERE execution_id = v_execution_id;
        
        RAISE NOTICE 'Error occurred: %', SQLERRM;
        RAISE;
END;
$$;

-- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –ø—Ä–æ—Ü–µ–¥—É—Ä–µ
COMMENT ON PROCEDURE ecommerce.process_orders_from_staging() IS
'–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–∫–∞–∑—ã –∏–∑ staging —Ç–∞–±–ª–∏—Ü—ã: –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ production';
```

### –®–∞–≥ 1.3: –°–æ–∑–¥–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–º–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä—ã #2 - –†–∞—Å—á–µ—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ–≤

```sql
-- ==========================================
-- –ü–†–û–¶–ï–î–£–†–ê 2: –†–ê–°–ß–ï–¢ –î–ù–ï–í–ù–´–• –ê–ì–†–ï–ì–ê–¢–û–í
-- ==========================================

CREATE OR REPLACE PROCEDURE ecommerce.calculate_daily_summary(
    p_summary_date DATE DEFAULT CURRENT_DATE
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_start_time TIMESTAMP;
    v_end_time TIMESTAMP;
    v_execution_id INTEGER;
    v_total_orders INTEGER;
BEGIN
    v_start_time := CLOCK_TIMESTAMP();
    
    -- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    INSERT INTO ecommerce.etl_execution_log 
    (procedure_name, execution_date, start_time, status)
    VALUES 
    ('calculate_daily_summary', p_summary_date, v_start_time, 'RUNNING')
    RETURNING execution_id INTO v_execution_id;
    
    RAISE NOTICE 'Calculating daily summary for date: %', p_summary_date;
    
    -- ==========================================
    -- –†–ê–°–ß–ï–¢ –ê–ì–†–ï–ì–ê–¢–û–í
    -- ==========================================
    
    WITH daily_metrics AS (
        SELECT 
            p_summary_date as summary_date,
            COUNT(*) as total_orders,
            SUM(total_amount) as total_revenue,
            SUM(discount_amount) as total_discount,
            AVG(total_amount) as avg_order_value,
            COUNT(DISTINCT customer_id) as unique_customers,
            COUNT(DISTINCT product_id) as unique_products
        FROM ecommerce.orders
        WHERE order_date = p_summary_date
    ),
    top_region_calc AS (
        SELECT region
        FROM ecommerce.orders
        WHERE order_date = p_summary_date
        GROUP BY region
        ORDER BY SUM(total_amount) DESC
        LIMIT 1
    )
    INSERT INTO ecommerce.daily_sales_summary (
        summary_date, total_orders, total_revenue, total_discount,
        avg_order_value, unique_customers, unique_products, top_region
    )
    SELECT 
        dm.summary_date,
        dm.total_orders,
        dm.total_revenue,
        dm.total_discount,
        dm.avg_order_value,
        dm.unique_customers,
        dm.unique_products,
        tr.region
    FROM daily_metrics dm
    CROSS JOIN top_region_calc tr
    ON CONFLICT (summary_date) DO UPDATE SET
        total_orders = EXCLUDED.total_orders,
        total_revenue = EXCLUDED.total_revenue,
        total_discount = EXCLUDED.total_discount,
        avg_order_value = EXCLUDED.avg_order_value,
        unique_customers = EXCLUDED.unique_customers,
        unique_products = EXCLUDED.unique_products,
        top_region = EXCLUDED.top_region,
        calculated_at = CURRENT_TIMESTAMP;
    
    GET DIAGNOSTICS v_total_orders = ROW_COUNT;
    
    v_end_time := CLOCK_TIMESTAMP();
    
    -- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    UPDATE ecommerce.etl_execution_log
    SET 
        end_time = v_end_time,
        duration_seconds = EXTRACT(EPOCH FROM (v_end_time - v_start_time))::INTEGER,
        rows_processed = v_total_orders,
        status = 'SUCCESS'
    WHERE execution_id = v_execution_id;
    
    RAISE NOTICE 'Daily summary calculated successfully for %', p_summary_date;
    
EXCEPTION
    WHEN OTHERS THEN
        UPDATE ecommerce.etl_execution_log
        SET 
            end_time = CLOCK_TIMESTAMP(),
            status = 'FAILED',
            error_message = SQLERRM
        WHERE execution_id = v_execution_id;
        
        RAISE;
END;
$$;

COMMENT ON PROCEDURE ecommerce.calculate_daily_summary(DATE) IS
'–í—ã—á–∏—Å–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –ø—Ä–æ–¥–∞–∂ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç—ã';
```

### –®–∞–≥ 1.4: –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤

```sql
-- ==========================================
-- –ü–†–û–¶–ï–î–£–†–ê 3: –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –õ–û–ì–û–í
-- ==========================================

CREATE OR REPLACE PROCEDURE ecommerce.cleanup_old_logs(
    p_retention_days INTEGER DEFAULT 90
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_deleted_count INTEGER;
    v_cutoff_date DATE;
BEGIN
    v_cutoff_date := CURRENT_DATE - p_retention_days;
    
    RAISE NOTICE 'Cleaning up execution logs older than %', v_cutoff_date;
    
    DELETE FROM ecommerce.etl_execution_log
    WHERE execution_date < v_cutoff_date;
    
    GET DIAGNOSTICS v_deleted_count = ROW_COUNT;
    
    RAISE NOTICE 'Deleted % old log records', v_deleted_count;
    
    -- –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    ANALYZE ecommerce.etl_execution_log;
END;
$$;

COMMENT ON PROCEDURE ecommerce.cleanup_old_logs(INTEGER) IS
'–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ –ª–æ–≥–æ–≤ —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π';
```

### –®–∞–≥ 1.5: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```sql
-- ==========================================
-- –ó–ê–ì–†–£–ó–ö–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•
-- ==========================================

-- –û—á–∏—Å—Ç–∫–∞ staging
TRUNCATE TABLE ecommerce.orders_staging;

-- –í—Å—Ç–∞–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–∫–∞–∑–æ–≤
INSERT INTO ecommerce.orders_staging 
(order_id, customer_id, product_id, quantity, unit_price, discount_percent, 
 order_date, order_time, status, region)
VALUES
    (1001, 101, 501, 2, 599.99, 10.00, CURRENT_DATE, '10:30:00', 'completed', 'North'),
    (1002, 102, 502, 1, 1299.99, 5.00, CURRENT_DATE, '11:15:00', 'completed', 'South'),
    (1003, 103, 503, 3, 49.99, 0.00, CURRENT_DATE, '12:00:00', 'completed', 'East'),
    (1004, 101, 504, 1, 299.99, 15.00, CURRENT_DATE, '13:30:00', 'pending', 'North'),
    (1005, 104, 501, 2, 599.99, 10.00, CURRENT_DATE, '14:00:00', 'completed', 'West'),
    (1006, 105, 505, 5, 19.99, 20.00, CURRENT_DATE, '15:45:00', 'completed', 'South'),
    (1007, 102, 502, 1, 1299.99, 5.00, CURRENT_DATE, '16:20:00', 'completed', 'East'),
    (1008, 106, 503, 4, 49.99, 0.00, CURRENT_DATE, '17:00:00', 'completed', 'North');

-- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
SELECT COUNT(*) as staging_count FROM ecommerce.orders_staging;
```

### –®–∞–≥ 1.6: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä –≤—Ä—É—á–Ω—É—é

```sql
-- ==========================================
-- –†–£–ß–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–¶–ï–î–£–†
-- ==========================================

-- –¢–µ—Å—Ç 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫–∞–∑–æ–≤
CALL ecommerce.process_orders_from_staging();

-- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
SELECT * FROM ecommerce.orders ORDER BY order_id;
SELECT * FROM ecommerce.etl_execution_log ORDER BY execution_id DESC LIMIT 5;

-- –¢–µ—Å—Ç 2: –†–∞—Å—á–µ—Ç –¥–Ω–µ–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
CALL ecommerce.calculate_daily_summary(CURRENT_DATE);

-- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
SELECT * FROM ecommerce.daily_sales_summary ORDER BY summary_date DESC;

-- –¢–µ—Å—Ç 3: –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ç–µ—Å—Ç —Å 0 –¥–Ω–µ–π)
CALL ecommerce.cleanup_old_logs(0);
```

---

## –ß–∞—Å—Ç—å 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Apache Airflow (20 –º–∏–Ω—É—Ç)

### –®–∞–≥ 2.1: –°–æ–∑–¥–∞–Ω–∏–µ Connection –≤ Airflow

1. –û—Ç–∫—Ä–æ–π—Ç–µ Airflow Web UI
2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ **Admin ‚Üí Connections**
3. –ù–∞–∂–º–∏—Ç–µ **+** (Add connection)
4. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```
Connection Id:    greenplum_prod
Connection Type:  Postgres
Host:             c-xxxxx.rw.mdb.yandexcloud.net
Schema:           postgres
Login:            admin
Password:         ********
Port:             6432
Extra:            {"sslmode": "require", "connect_timeout": 10}
```

5. –ù–∞–∂–º–∏—Ç–µ **Test** –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
6. –ù–∞–∂–º–∏—Ç–µ **Save**

### –®–∞–≥ 2.2: –°–æ–∑–¥–∞–Ω–∏–µ DAG —Ñ–∞–π–ª–∞

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `dag_greenplum_procedures.py`:

```python
"""
DAG –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ö—Ä–∞–Ω–∏–º—ã—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä GreenPlum
–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫–∞–∑–æ–≤ e-commerce –º–∞–≥–∞–∑–∏–Ω–∞
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.operators.python import PythonOperator
from airflow.operators.dummy import DummyOperator

# ==========================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø DAG
# ==========================================

default_args = {
    'owner': 'data-engineer',
    'depends_on_past': False,
    'start_date': datetime(2025, 1, 1),
    'email': ['alerts@company.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'retry_exponential_backoff': True,
    'max_retry_delay': timedelta(minutes=30),
}

dag = DAG(
    'greenplum_daily_orders_etl',
    default_args=default_args,
    description='Daily ETL: Process orders and calculate sales summary',
    schedule_interval='0 2 * * *',  # –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 2:00 UTC
    catchup=False,
    tags=['greenplum', 'etl', 'procedures', 'ecommerce'],
    doc_md="""
    # Daily Orders ETL Pipeline
    
    –≠—Ç–æ—Ç DAG –≤—ã–ø–æ–ª–Ω—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–∫–∞–∑–æ–≤:
    1. –í—ã–∑—ã–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–∫–∞–∑–æ–≤ –∏–∑ staging
    2. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã
    3. –û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –ª–æ–≥–∏ (—Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é)
    
    ## –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ
    - –ó–∞–ø—É—Å–∫: –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 02:00 UTC
    - –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤: –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 03:00 UTC
    
    ## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    - –õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ecommerce.etl_execution_log
    - –ê–ª–µ—Ä—Ç—ã: email –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    """
)

# ==========================================
# –ó–ê–î–ê–ß–ò DAG
# ==========================================

# –ó–∞–¥–∞—á–∞ 0: –ù–∞—á–∞–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
start = DummyOperator(
    task_id='start',
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ staging
check_staging_data = PostgresOperator(
    task_id='check_staging_has_data',
    postgres_conn_id='greenplum_prod',
    sql="""
        DO $$
        DECLARE
            v_count INTEGER;
        BEGIN
            SELECT COUNT(*) INTO v_count 
            FROM ecommerce.orders_staging;
            
            IF v_count = 0 THEN
                RAISE WARNING 'No data in staging table';
            ELSE
                RAISE NOTICE 'Found % records in staging', v_count;
            END IF;
        END $$;
    """,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 2: –í—ã–∑–æ–≤ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–∫–∞–∑–æ–≤
process_orders = PostgresOperator(
    task_id='process_orders_from_staging',
    postgres_conn_id='greenplum_prod',
    sql="CALL ecommerce.process_orders_from_staging();",
    autocommit=True,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 3: –í—ã–∑–æ–≤ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã —Ä–∞—Å—á–µ—Ç–∞ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
calculate_summary = PostgresOperator(
    task_id='calculate_daily_summary',
    postgres_conn_id='greenplum_prod',
    sql="CALL ecommerce.calculate_daily_summary(CURRENT_DATE);",
    autocommit=True,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
def verify_execution(**context):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ç–∞–±–ª–∏—Ü—É –ª–æ–≥–æ–≤
    """
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    
    hook = PostgresHook(postgres_conn_id='greenplum_prod')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ª–æ–≥–µ
    query = """
        SELECT 
            procedure_name,
            status,
            rows_processed,
            duration_seconds,
            error_message
        FROM ecommerce.etl_execution_log
        WHERE execution_date = CURRENT_DATE
        ORDER BY execution_id DESC
        LIMIT 10;
    """
    
    results = hook.get_records(query)
    
    print("=" * 70)
    print("EXECUTION LOG - Last 10 records for today")
    print("=" * 70)
    
    failed_procedures = []
    for row in results:
        proc_name, status, rows, duration, error = row
        print(f"Procedure: {proc_name:<30} | Status: {status:<10}")
        print(f"  Rows processed: {rows or 0:<10} | Duration: {duration or 0} sec")
        if error:
            print(f"  Error: {error}")
            failed_procedures.append(proc_name)
        print("-" * 70)
    
    if failed_procedures:
        raise Exception(f"Failed procedures: {', '.join(failed_procedures)}")
    
    print("All procedures executed successfully!")

verify_results = PythonOperator(
    task_id='verify_execution_results',
    python_callable=verify_execution,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
def generate_daily_report(**context):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂–∞—Ö
    """
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    
    hook = PostgresHook(postgres_conn_id='greenplum_prod')
    
    query = """
        SELECT 
            summary_date,
            total_orders,
            total_revenue,
            total_discount,
            avg_order_value,
            unique_customers,
            unique_products,
            top_region
        FROM ecommerce.daily_sales_summary
        WHERE summary_date = CURRENT_DATE;
    """
    
    result = hook.get_first(query)
    
    if result:
        date, orders, revenue, discount, avg_val, customers, products, region = result
        
        print("\n" + "=" * 70)
        print(f"DAILY SALES REPORT - {date}")
        print("=" * 70)
        print(f"Total Orders:        {orders:>10}")
        print(f"Total Revenue:       ${revenue:>10,.2f}")
        print(f"Total Discount:      ${discount:>10,.2f}")
        print(f"Average Order Value: ${avg_val:>10,.2f}")
        print(f"Unique Customers:    {customers:>10}")
        print(f"Unique Products:     {products:>10}")
        print(f"Top Region:          {region:>10}")
        print("=" * 70 + "\n")
        
        # –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å email –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª
        context['ti'].xcom_push(key='daily_revenue', value=float(revenue))
        context['ti'].xcom_push(key='daily_orders', value=int(orders))
    else:
        print("No summary data found for today")

generate_report = PythonOperator(
    task_id='generate_daily_report',
    python_callable=generate_daily_report,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 6: –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—è–º)
cleanup_logs = PostgresOperator(
    task_id='cleanup_old_logs',
    postgres_conn_id='greenplum_prod',
    sql="CALL ecommerce.cleanup_old_logs(90);",  # –•—Ä–∞–Ω–∏–º 90 –¥–Ω–µ–π
    autocommit=True,
    dag=dag,
)

# –ó–∞–¥–∞—á–∞ 7: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
end = DummyOperator(
    task_id='end',
    dag=dag,
)

# ==========================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
# ==========================================

# –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫
start >> check_staging_data >> process_orders >> calculate_summary
calculate_summary >> verify_results >> generate_report

# –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø–æ—Ç–æ–∫–æ–º)
start >> cleanup_logs

# –í—Å–µ —Å—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ
[generate_report, cleanup_logs] >> end
```

### –®–∞–≥ 2.3: –ó–∞–≥—Ä—É–∑–∫–∞ DAG –≤ Airflow

```bash
# –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ª–æ–∫–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É Airflow
cp dag_greenplum_procedures.py ~/airflow/dags/

# –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Yandex Managed Airflow
aws s3 cp dag_greenplum_procedures.py s3://your-bucket/dags/ \
  --endpoint-url=https://storage.yandexcloud.net
```

---

## –ß–∞—Å—Ç—å 3: –ó–∞–ø—É—Å–∫ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (15 –º–∏–Ω—É—Ç)

### –®–∞–≥ 3.1: –ê–∫—Ç–∏–≤–∞—Ü–∏—è DAG

1. –û—Ç–∫—Ä–æ–π—Ç–µ Airflow Web UI
2. –ù–∞–π–¥–∏—Ç–µ DAG `greenplum_daily_orders_etl`
3. –í–∫–ª—é—á–∏—Ç–µ DAG (toggle –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å)
4. –ù–∞–∂–º–∏—Ç–µ **Trigger DAG** –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞

### –®–∞–≥ 3.2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

**–í Airflow UI:**

1. **Graph View** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á –∏ –∏—Ö —Å—Ç–∞—Ç—É—Å–æ–≤
2. **Gantt Chart** - –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
3. **Task Logs** - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
4. **XCom** - –¥–∞–Ω–Ω—ã–µ, –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏

**–í GreenPlum:**

```sql
-- –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
SELECT 
    execution_id,
    procedure_name,
    execution_date,
    TO_CHAR(start_time, 'HH24:MI:SS') as start_time,
    TO_CHAR(end_time, 'HH24:MI:SS') as end_time,
    duration_seconds,
    rows_processed,
    status,
    CASE 
        WHEN error_message IS NOT NULL 
        THEN LEFT(error_message, 50) || '...'
        ELSE 'OK'
    END as error_summary
FROM ecommerce.etl_execution_log
WHERE execution_date >= CURRENT_DATE - 7
ORDER BY execution_id DESC;

-- –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–Ω–µ–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
SELECT 
    summary_date,
    total_orders,
    TO_CHAR(total_revenue, 'FM$999,999,990.00') as revenue,
    unique_customers,
    TO_CHAR(avg_order_value, 'FM$9,990.00') as avg_order,
    top_region
FROM ecommerce.daily_sales_summary
ORDER BY summary_date DESC
LIMIT 30;
```

### –®–∞–≥ 3.3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```sql
-- –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∑–∞–∫–∞–∑–∞–º
SELECT 
    order_date,
    region,
    COUNT(*) as orders,
    SUM(total_amount) as revenue,
    AVG(total_amount) as avg_order
FROM ecommerce.orders
WHERE order_date >= CURRENT_DATE - 7
GROUP BY order_date, region
ORDER BY order_date DESC, revenue DESC;

-- –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Ü–µ–¥—É—Ä
SELECT 
    procedure_name,
    COUNT(*) as executions,
    AVG(duration_seconds) as avg_duration,
    MAX(duration_seconds) as max_duration,
    MIN(duration_seconds) as min_duration,
    SUM(CASE WHEN status = 'SUCCESS' THEN 1 ELSE 0 END) as success_count,
    SUM(CASE WHEN status = 'FAILED' THEN 1 ELSE 0 END) as failed_count
FROM ecommerce.etl_execution_log
WHERE execution_date >= CURRENT_DATE - 30
GROUP BY procedure_name;
```

---

## –ß–∞—Å—Ç—å 4: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã

```python
# –í DAG –¥–æ–±–∞–≤—å—Ç–µ –∑–∞–¥–∞—á—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
from airflow.models import Variable

process_date = "{{ ds }}"  # –î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è DAG

calculate_custom_summary = PostgresOperator(
    task_id='calculate_summary_for_date',
    postgres_conn_id='greenplum_prod',
    sql=f"CALL ecommerce.calculate_daily_summary('{process_date}');",
    autocommit=True,
    dag=dag,
)
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –£—Å–ª–æ–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ–¥—É—Ä

```python
from airflow.operators.python import BranchPythonOperator

def check_if_weekend(**context):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏"""
    from datetime import datetime
    execution_date = context['execution_date']
    
    # 5 = Saturday, 6 = Sunday
    if execution_date.weekday() in [5, 6]:
        return 'weekend_procedure'
    else:
        return 'weekday_procedure'

branch_task = BranchPythonOperator(
    task_id='check_day_of_week',
    python_callable=check_if_weekend,
    dag=dag,
)

weekend_proc = PostgresOperator(
    task_id='weekend_procedure',
    postgres_conn_id='greenplum_prod',
    sql="CALL ecommerce.weekend_special_processing();",
    dag=dag,
)

weekday_proc = PostgresOperator(
    task_id='weekday_procedure',
    postgres_conn_id='greenplum_prod',
    sql="CALL ecommerce.process_orders_from_staging();",
    dag=dag,
)

branch_task >> [weekend_proc, weekday_proc]
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ü–µ–¥—É—Ä

```python
from airflow.operators.python import PythonOperator

def execute_procedure_list(**context):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ü–µ–¥—É—Ä –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    
    procedures = [
        'ecommerce.process_orders_from_staging()',
        'ecommerce.calculate_daily_summary(CURRENT_DATE)',
        'ecommerce.update_customer_segments()',
        'ecommerce.refresh_product_recommendations()'
    ]
    
    hook = PostgresHook(postgres_conn_id='greenplum_prod')
    
    for proc in procedures:
        print(f"Executing: {proc}")
        hook.run(f"CALL {proc}")
        print(f"Completed: {proc}")

execute_all = PythonOperator(
    task_id='execute_procedure_list',
    python_callable=execute_procedure_list,
    dag=dag,
)
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç–∏–Ω–≥

### Dashboard –≤ GreenPlum

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ view –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
CREATE OR REPLACE VIEW ecommerce.etl_monitoring_dashboard AS
SELECT 
    -- –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    (SELECT COUNT(*) FROM ecommerce.orders WHERE order_date = CURRENT_DATE) as todays_orders,
    (SELECT SUM(total_amount) FROM ecommerce.orders WHERE order_date = CURRENT_DATE) as todays_revenue,
    
    -- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    (SELECT COUNT(*) FROM ecommerce.etl_execution_log 
     WHERE start_time >= CURRENT_TIMESTAMP - INTERVAL '24 hours' 
     AND status = 'SUCCESS') as successful_procedures_24h,
    
    (SELECT COUNT(*) FROM ecommerce.etl_execution_log 
     WHERE start_time >= CURRENT_TIMESTAMP - INTERVAL '24 hours' 
     AND status = 'FAILED') as failed_procedures_24h,
    
    -- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Ü–µ–¥—É—Ä
    (SELECT AVG(duration_seconds) FROM ecommerce.etl_execution_log 
     WHERE start_time >= CURRENT_TIMESTAMP - INTERVAL '24 hours') as avg_duration_24h,
    
    -- –ü–æ—Å–ª–µ–¥–Ω—è—è —É—Å–ø–µ—à–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    (SELECT MAX(end_time) FROM ecommerce.etl_execution_log 
     WHERE status = 'SUCCESS') as last_successful_run;

-- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
SELECT * FROM ecommerce.etl_monitoring_dashboard;
```

### Email –∞–ª–µ—Ä—Ç—ã –≤ Airflow

```python
from airflow.operators.email import EmailOperator

send_alert = EmailOperator(
    task_id='send_failure_alert',
    to='data-team@company.com',
    subject='[ALERT] GreenPlum ETL Failed',
    html_content="""
    <h3>ETL Execution Failed</h3>
    <p>Date: {{ ds }}</p>
    <p>DAG: {{ dag.dag_id }}</p>
    <p>Task: {{ task.task_id }}</p>
    <p>Check Airflow UI for details.</p>
    """,
    trigger_rule='one_failed',
    dag=dag,
)
```

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫

### –î–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —É–±–µ–¥–∏—Ç–µ—Å—å:

- [ ] GreenPlum –∫–ª–∞—Å—Ç–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –°–æ–∑–¥–∞–Ω—ã –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã
- [ ] Connection –≤ Airflow –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω
- [ ] DAG —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Airflow
- [ ] –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ staging —Ç–∞–±–ª–∏—Ü–µ
- [ ] –ü—Ä–æ—Ü–µ–¥—É—Ä—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤—Ä—É—á–Ω—É—é
- [ ] Security Groups —Ä–∞–∑—Ä–µ—à–∞—é—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
- [ ] SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã

---

## üéØ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è DAG –≤—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å:

1. **–í Airflow UI:**
   - –í—Å–µ –∑–∞–¥–∞—á–∏ –∑–µ–ª–µ–Ω—ã–µ (success)
   - –õ–æ–≥–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä
   - XCom —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç—Ä–∏–∫–∏ (revenue, orders)

2. **–í GreenPlum:**
   - –¢–∞–±–ª–∏—Ü–∞ `orders` —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑—ã
   - –¢–∞–±–ª–∏—Ü–∞ `daily_sales_summary` –æ–±–Ω–æ–≤–ª–µ–Ω–∞
   - –¢–∞–±–ª–∏—Ü–∞ `etl_execution_log` —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–∏ SUCCESS

3. **–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**
   - process_orders: ~5-10 —Å–µ–∫—É–Ω–¥ –¥–ª—è 1000 –∑–∞–ø–∏—Å–µ–π
   - calculate_summary: ~2-5 —Å–µ–∫—É–Ω–¥
   - –í–µ—Å—å DAG: ~1-2 –º–∏–Ω—É—Ç—ã

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Connection timeout

```bash
# –†–µ—à–µ–Ω–∏–µ: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Security Groups
yc vpc security-group list-rules <SECURITY_GROUP_ID>

# –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è:
# - –í—Ö–æ–¥—è—â–∏–π —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –ø–æ—Ä—Ç 6432 (GreenPlum)
# - –ò—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–∞—Ñ–∏–∫ –æ—Ç Airflow
```

### –ü—Ä–æ–±–ª–µ–º–∞: Process execution failed

```sql
-- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ GreenPlum
SELECT * FROM ecommerce.etl_execution_log 
WHERE status = 'FAILED' 
ORDER BY execution_id DESC 
LIMIT 5;

-- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
SELECT COUNT(*) FROM ecommerce.orders_staging;
```

### –ü—Ä–æ–±–ª–µ–º–∞: SSL connection error

```python
# –í Connection –¥–æ–±–∞–≤—å—Ç–µ –≤ Extra:
{
    "sslmode": "require",
    "sslrootcert": "/path/to/ca.pem"  # –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
}
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [PostgresOperator Documentation](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/operators/postgres_operator_howto_guide.html)
- [GreenPlum Stored Procedures](https://docs.greenplum.org/6-24/admin_guide/query/topics/functions-operators.html)
- [Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)

---

**–í–µ—Ä—Å–∏—è:** 1.0  
**–î–∞—Ç–∞:** –ù–æ—è–±—Ä—å 2025  
**–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:** Airflow 2.x, GreenPlum 6.x, Yandex Cloud
